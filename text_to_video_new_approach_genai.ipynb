{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-17T13:11:01.769316Z","iopub.status.busy":"2024-12-17T13:11:01.768958Z","iopub.status.idle":"2024-12-17T13:11:02.092672Z","shell.execute_reply":"2024-12-17T13:11:02.091782Z","shell.execute_reply.started":"2024-12-17T13:11:01.769266Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/sample-sales-data/sales_data_sample.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:11:02.094440Z","iopub.status.busy":"2024-12-17T13:11:02.094083Z","iopub.status.idle":"2024-12-17T13:13:22.558663Z","shell.execute_reply":"2024-12-17T13:13:22.557562Z","shell.execute_reply.started":"2024-12-17T13:11:02.094413Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting moviepy\n","  Downloading moviepy-2.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (5.1.1)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\n","Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n","  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\n","Collecting proglog<=1.0.0 (from moviepy)\n","  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.0.1)\n","Requirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (10.3.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\n","Downloading moviepy-2.1.1-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n","Installing collected packages: proglog, imageio_ffmpeg, moviepy\n","Successfully installed imageio_ffmpeg-0.5.1 moviepy-2.1.1 proglog-0.1.10\n","Requirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (2.1.1)\n","Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (5.1.1)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\n","Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\n","Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.0.1)\n","Requirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (10.3.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\n","Collecting gradio\n","  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.5.2 (from gradio)\n","  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.26.2)\n","Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.3)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\n","Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.1)\n","Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.8.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.42.0-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.2->gradio) (2024.6.0)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.2->gradio) (12.0)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n","  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.15.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gradio) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.27.1)\n","Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (1.26.18)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.8.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Installing collected packages: semantic-version, ruff, python-multipart, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: python-multipart\n","    Found existing installation: python-multipart 0.0.9\n","    Uninstalling python-multipart-0.0.9:\n","      Successfully uninstalled python-multipart-0.0.9\n","  Attempting uninstall: starlette\n","    Found existing installation: starlette 0.37.2\n","    Uninstalling starlette-0.37.2:\n","      Successfully uninstalled starlette-0.37.2\n","  Attempting uninstall: fastapi\n","    Found existing installation: fastapi 0.111.0\n","    Uninstalling fastapi-0.111.0:\n","      Successfully uninstalled fastapi-0.111.0\n","Successfully installed fastapi-0.115.6 ffmpy-0.4.0 gradio-5.9.1 gradio-client-1.5.2 python-multipart-0.0.20 ruff-0.8.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3\n","Collecting langchain\n","  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n","  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n","  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.3,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.2.3-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.10.1)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n","Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.25->langchain)\n","  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.4)\n","Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (2.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.0)\n","Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n","Downloading langsmith-0.2.3-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: requests-toolbelt\n","    Found existing installation: requests-toolbelt 0.10.1\n","    Uninstalling requests-toolbelt-0.10.1:\n","      Successfully uninstalled requests-toolbelt-0.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.10.1 requires cubinlinker, which is not installed.\n","cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n","cudf 24.10.1 requires ptxcompiler, which is not installed.\n","cuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 24.10.0 requires cuvs==24.10.*, which is not installed.\n","cuml 24.10.0 requires nvidia-cublas, which is not installed.\n","cuml 24.10.0 requires nvidia-cufft, which is not installed.\n","cuml 24.10.0 requires nvidia-curand, which is not installed.\n","cuml 24.10.0 requires nvidia-cusolver, which is not installed.\n","cuml 24.10.0 requires nvidia-cusparse, which is not installed.\n","dask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","pylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\n","cudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n","cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n","dask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n","distributed 2024.9.0 requires dask==2024.9.0, but you have dask 2024.11.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\n","jupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n","plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n","pylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\n","rapids-dask-dependency 24.10.0a0 requires dask==2024.9.0, but you have dask 2024.11.2 which is incompatible.\n","rapids-dask-dependency 24.10.0a0 requires dask-expr==1.1.14, but you have dask-expr 1.1.19 which is incompatible.\n","thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","ydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 langsmith-0.2.3 packaging-24.2 requests-toolbelt-1.0.0\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n","Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","Collecting langchain_community\n","  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n","Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.12 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.12)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.25)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (0.3.3)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (2.10.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.4)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.5)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community) (2.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (2.27.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.0)\n","Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n","Installing collected packages: httpx-sse, pydantic-settings, langchain_community\n","Successfully installed httpx-sse-0.4.0 langchain_community-0.3.12 pydantic-settings-2.7.0\n","Requirement already satisfied: moviepy in /opt/conda/lib/python3.10/site-packages (2.1.1)\n","Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (5.1.1)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\n","Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\n","Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.0.1)\n","Requirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (10.3.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\n","Collecting openai\n","  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.1)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n","Downloading openai-1.57.4-py3-none-any.whl (390 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, openai\n","Successfully installed jiter-0.8.2 openai-1.57.4\n","\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement dateime (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for dateime\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n","\u001b[0mCollecting diffusers\n","  Downloading diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (7.0.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.15.1)\n","Requirement already satisfied: huggingface-hub>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.26.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.5)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.3.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.6.2)\n","Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: diffusers\n","Successfully installed diffusers-0.31.0\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Collecting editor\n","  Downloading editor-1.6.6-py3-none-any.whl.metadata (2.3 kB)\n","Collecting runs (from editor)\n","  Downloading runs-1.2.2-py3-none-any.whl.metadata (10 kB)\n","Collecting xmod (from editor)\n","  Downloading xmod-1.8.1-py3-none-any.whl.metadata (1.8 kB)\n","Downloading editor-1.6.6-py3-none-any.whl (4.0 kB)\n","Downloading runs-1.2.2-py3-none-any.whl (7.0 kB)\n","Downloading xmod-1.8.1-py3-none-any.whl (4.6 kB)\n","Installing collected packages: xmod, runs, editor\n","Successfully installed editor-1.6.6 runs-1.2.2 xmod-1.8.1\n","\u001b[31mERROR: Could not find a version that satisfies the requirement dalle (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for dalle\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Import necessary libraries\n","# Installing necessary libraries\n","!pip install moviepy\n","!pip install moviepy\n","!pip install gradio\n","!pip install langchain\n","!pip install transformers\n","!pip install pandas\n","!pip install numpy \n","!pip install langchain_community\n","!pip install moviepy\n","!pip install openai\n","!pip install os\n","!pip install numpy\n","!pip install dateime\n","!pip install os\n","!pip install diffusers\n","!pip install torch\n","!pip install editor\n","!pip install dalle"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:22.560539Z","iopub.status.busy":"2024-12-17T13:13:22.560228Z","iopub.status.idle":"2024-12-17T13:13:35.629130Z","shell.execute_reply":"2024-12-17T13:13:35.628153Z","shell.execute_reply.started":"2024-12-17T13:13:22.560511Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gtts\n","  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /opt/conda/lib/python3.10/site-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->gtts) (2024.6.2)\n","Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.5.4\n"]}],"source":["!pip install gtts\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import numpy as np\n","import os\n","import torch\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n","import gtts  # For text-to-speech audio generation\n","# from langchain_community import LangChain  # For implementing langchain and other NLP tasks\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.631580Z","iopub.status.busy":"2024-12-17T13:13:35.631134Z","iopub.status.idle":"2024-12-17T13:13:35.639870Z","shell.execute_reply":"2024-12-17T13:13:35.639009Z","shell.execute_reply.started":"2024-12-17T13:13:35.631524Z"},"trusted":true},"outputs":[],"source":["def nlp_pipeline(text, data):\n","    # Use T5 for summarization\n","    summary_model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n","    summary_tokenizer = AutoTokenizer.from_pretrained('t5-base')\n","    \n","    # Prepare input\n","    input_text = f\"summarize: {text} {data}\"\n","    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n","    \n","    # Generate summary\n","    outputs = summary_model.generate(inputs, max_length=100)\n","    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    \n","    # Extract percentages and categories using simpler regex patterns\n","    import re\n","    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n","    words = text.split()\n","    categories = []\n","    \n","    # Find words after \"use\" or \"uses\"\n","    for i, word in enumerate(words):\n","        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n","            categories.append(words[i + 1])\n","    \n","    if not percentages or not categories:\n","        percentages = [100]\n","        categories = ['Summary']\n","    \n","    # Generate audio\n","    tts = gtts.gTTS(summary_text, lang='en')\n","    tts.save('summary_audio.mp3')\n","    \n","    return {\n","        'categories': categories,\n","        'values': percentages,\n","        'text': summary_text\n","    }"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.641133Z","iopub.status.busy":"2024-12-17T13:13:35.640878Z","iopub.status.idle":"2024-12-17T13:13:35.695389Z","shell.execute_reply":"2024-12-17T13:13:35.694576Z","shell.execute_reply.started":"2024-12-17T13:13:35.641109Z"},"trusted":true},"outputs":[],"source":["# Define a function to generate infographics from CSV file with dynamic visualization selection\n","def generate_infographics_from_csv(csv_file):\n","    # Read the CSV file with error handling for UnicodeDecodeError\n","    try:\n","        df = pd.read_csv(csv_file)\n","    except UnicodeDecodeError:\n","        df = pd.read_csv(csv_file, encoding='utf-8', errors='replace')\n","    \n","    # Determine the best visualization method based on data characteristics\n","    if len(df) <= 10:  # For small datasets, a pie chart is suitable\n","        visualization_method = 'pie_chart'\n","    elif len(df) <= 50:  # For medium-sized datasets, a bar chart is suitable\n","        visualization_method = 'bar_chart'\n","    elif len(df) <= 100:  # For larger datasets, a line chart is suitable\n","        visualization_method = 'line_chart'\n","    else:  # For even larger datasets, consider using more advanced visualization tools or libraries\n","        visualization_method = 'advanced_visualization'\n","    \n","    # Generate the selected visualization\n","    if visualization_method == 'bar_chart':\n","        fig, ax = plt.subplots()\n","        ax.bar(df['Category'], df['Value'])\n","        ax.set_title('Bar Chart')\n","        ax.set_xlabel('Category')\n","        ax.set_ylabel('Value')\n","        plt.savefig('bar_chart.png')\n","    elif visualization_method == 'pie_chart':\n","        fig, ax = plt.subplots()\n","        ax.pie(df['Value'], labels=df['Category'], autopct='%1.1f%%')\n","        ax.set_title('Pie Chart')\n","        ax.axis('equal')\n","        plt.savefig('pie_chart.png')\n","    elif visualization_method == 'line_chart':\n","        fig, ax = plt.subplots()\n","        ax.plot(df['Category'], df['Value'])\n","        ax.set_title('Line Chart')\n","        ax.set_xlabel('Category')\n","        ax.set_ylabel('Value')\n","        plt.savefig('line_chart.png')\n","    elif visualization_method == 'advanced_visualization':\n","        # For larger datasets, consider using more advanced visualization tools or libraries\n","        # such as seaborn, plotly, or bokeh to handle large datasets and process the data\n","        # Example using seaborn\n","        import seaborn as sns\n","        sns.set_theme(style=\"whitegrid\")\n","        sns.barplot(data=df, x='Category', y='Value')\n","        plt.title('Advanced Visualization')\n","        plt.xlabel('Category')\n","        plt.ylabel('Value')\n","        plt.savefig('advanced_visualization.png')\n","    \n","    # Save the generated image\n","    plt.savefig(f'{visualization_method}.png')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.696680Z","iopub.status.busy":"2024-12-17T13:13:35.696398Z","iopub.status.idle":"2024-12-17T13:13:35.713227Z","shell.execute_reply":"2024-12-17T13:13:35.712599Z","shell.execute_reply.started":"2024-12-17T13:13:35.696656Z"},"trusted":true},"outputs":[],"source":["# Define a function to generate infographics from custom prompt and CSV file\n","def generate_infographics_from_prompt_and_csv(prompt, csv_file):\n","    # Use the NLP pipeline to process the prompt and CSV file\n","    summary = nlp_pipeline(prompt, pd.read_csv(csv_file)['Category'].tolist())\n","    \n","    # Integrate with AI models like GPT-3 for more dynamic and interactive visualizations\n","    # Assuming GPT-3 is available and can generate images based on the summary\n","    # For demonstration, we'll use matplotlib for a simple visualization\n","    fig, ax = plt.subplots()\n","    ax.bar(summary['categories'], summary['values'])\n","    ax.set_title('Infographics from CSV and Prompt')\n","    ax.set_xlabel('Category')\n","    ax.set_ylabel('Value')\n","    plt.savefig('infographics_image.png')\n","    images = ['infographics_image.png']\n","    \n","    # Create a video from the images using moviepy\n","    from moviepy.editor import ImageSequenceClip\n","    clip = ImageSequenceClip(images, fps=1)\n","    clip.write_videofile('infographics_video.mp4')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.714674Z","iopub.status.busy":"2024-12-17T13:13:35.714378Z","iopub.status.idle":"2024-12-17T13:13:35.731467Z","shell.execute_reply":"2024-12-17T13:13:35.730854Z","shell.execute_reply.started":"2024-12-17T13:13:35.714649Z"},"trusted":true},"outputs":[],"source":["def create_animated_gif(text):\n","    import os\n","    from PIL import Image\n","    import matplotlib.pyplot as plt\n","    \n","    # Use the NLP pipeline to process the text\n","    summary = nlp_pipeline(text, '')\n","    categories = summary['categories']\n","    values = summary['values']\n","    \n","    # Create frames directory\n","    frames_dir = 'animation_frames'\n","    os.makedirs(frames_dir, exist_ok=True)\n","    \n","    def create_frame(frame_number, value_multiplier, categories=categories, values=values):  # Pass values as parameter\n","        fig, ax = plt.subplots(figsize=(12, 7))\n","        \n","        # Calculate current height of bars\n","        current_values = [v * value_multiplier for v in values]\n","        \n","        # Create bars with current height\n","        bars = ax.bar(categories, current_values, color='skyblue')\n","        \n","        # Styling\n","        ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n","        ax.set_xlabel('Brands', fontsize=14)\n","        ax.set_ylabel('Percentage (%)', fontsize=14)\n","        ax.set_ylim(0, max(values) * 1.2)\n","        \n","        # Add value labels\n","        for bar, value in zip(bars, current_values):\n","            if value > 0:\n","                height = bar.get_height()\n","                ax.text(bar.get_x() + bar.get_width()/2., height,\n","                       f'{int(value)}%',\n","                       ha='center', va='bottom', fontsize=12)\n","        \n","        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n","        plt.tight_layout()\n","        \n","        # Save frame\n","        frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n","        plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n","        plt.close()\n","        return frame_path\n","    \n","    # Generate frames\n","    frames = []\n","    num_frames = 20  # Number of frames for animation\n","    \n","    print(\"Generating frames...\")\n","    for i in range(num_frames + 1):\n","        multiplier = i / num_frames\n","        frame_path = create_frame(i, multiplier)\n","        frames.append(frame_path)\n","    \n","    # Create GIF\n","    print(\"Creating GIF...\")\n","    images = [Image.open(f) for f in frames]\n","    \n","    gif_path = 'animated_infographic.gif'\n","    images[0].save(\n","        gif_path,\n","        save_all=True,\n","        append_images=images[1:],\n","        duration=100,  # 100ms between frames\n","        loop=0\n","    )\n","    \n","    # Clean up frames\n","    for frame in frames:\n","        os.remove(frame)\n","    os.rmdir(frames_dir)\n","    \n","    print(f\"Animation saved as GIF: {gif_path}\")\n","    return gif_path"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.732770Z","iopub.status.busy":"2024-12-17T13:13:35.732449Z","iopub.status.idle":"2024-12-17T13:13:35.750095Z","shell.execute_reply":"2024-12-17T13:13:35.749241Z","shell.execute_reply.started":"2024-12-17T13:13:35.732746Z"},"trusted":true},"outputs":[],"source":["def create_animated_gif(text):\n","    import os\n","    from PIL import Image\n","    import matplotlib.pyplot as plt\n","    import shutil  # For directory removal\n","    \n","    # Use the NLP pipeline to process the text\n","    summary = nlp_pipeline(text, '')\n","    categories = summary['categories']\n","    values = summary['values']\n","    \n","    # Create frames directory\n","    frames_dir = 'animation_frames'\n","    if os.path.exists(frames_dir):\n","        shutil.rmtree(frames_dir)  # Remove directory if it exists\n","    os.makedirs(frames_dir)\n","    \n","    def create_frame(frame_number, value_multiplier, categories=categories, values=values):\n","        fig, ax = plt.subplots(figsize=(12, 7))\n","        \n","        # Calculate current height of bars\n","        current_values = [v * value_multiplier for v in values]\n","        \n","        # Create bars with current height\n","        bars = ax.bar(categories, current_values, color='skyblue')\n","        \n","        # Styling\n","        ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n","        ax.set_xlabel('Brands', fontsize=14)\n","        ax.set_ylabel('Percentage (%)', fontsize=14)\n","        ax.set_ylim(0, max(values) * 1.2)\n","        \n","        # Add value labels\n","        for bar, value in zip(bars, current_values):\n","            if value > 0:\n","                height = bar.get_height()\n","                ax.text(bar.get_x() + bar.get_width()/2., height,\n","                       f'{int(value)}%',\n","                       ha='center', va='bottom', fontsize=12)\n","        \n","        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n","        plt.tight_layout()\n","        \n","        # Save frame\n","        frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n","        plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n","        plt.close()\n","        return frame_path\n","    \n","    # Generate frames\n","    frames = []\n","    num_frames = 20  # Number of frames for animation\n","    \n","    print(\"Generating frames...\")\n","    for i in range(num_frames + 1):\n","        multiplier = i / num_frames\n","        frame_path = create_frame(i, multiplier)\n","        frames.append(frame_path)\n","    \n","    # Create GIF\n","    print(\"Creating GIF...\")\n","    images = [Image.open(f) for f in frames]\n","    \n","    gif_path = 'animated_infographic.gif'\n","    images[0].save(\n","        gif_path,\n","        save_all=True,\n","        append_images=images[1:],\n","        duration=100,  # 100ms between frames\n","        loop=0\n","    )\n","    \n","    # Clean up frames directory\n","    try:\n","        shutil.rmtree(frames_dir)\n","        print(\"Cleanup completed successfully\")\n","    except Exception as e:\n","        print(f\"Cleanup error: {e}\")\n","    \n","    print(f\"Animation saved as GIF: {gif_path}\")\n","    return gif_path"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.751391Z","iopub.status.busy":"2024-12-17T13:13:35.751126Z","iopub.status.idle":"2024-12-17T13:13:35.764725Z","shell.execute_reply":"2024-12-17T13:13:35.763949Z","shell.execute_reply.started":"2024-12-17T13:13:35.751367Z"},"trusted":true},"outputs":[],"source":["\n","\n","def create_detailed_infographic(text):\n","    \"\"\"\n","    Creates a static detailed infographic for data storytelling\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    \n","    # Process text\n","    summary = nlp_pipeline(text, '')\n","    categories = summary['categories']\n","    values = summary['values']\n","    \n","    # Create figure with subplots\n","    fig = plt.figure(figsize=(15, 10))\n","    \n","    # Main bar plot\n","    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n","    bars = ax1.bar(categories, values, color='skyblue')\n","    ax1.set_title('Market Share Distribution', fontsize=16)\n","    ax1.set_ylabel('Percentage (%)')\n","    \n","    # Add value labels\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax1.text(bar.get_x() + bar.get_width()/2., height,\n","                f'{int(height)}%',\n","                ha='center', va='bottom')\n","    \n","    # Pie chart\n","    ax2 = plt.subplot2grid((2, 2), (1, 0))\n","    ax2.pie(values, labels=categories, autopct='%1.1f%%')\n","    ax2.set_title('Market Share Proportion')\n","    \n","    # Additional insights text\n","    ax3 = plt.subplot2grid((2, 2), (1, 1))\n","    ax3.axis('off')\n","    total = sum(values)\n","    insights_text = f\"\"\"Key Insights:\n","    \n","    • Total market coverage: {total}%\n","    • Leading brand: {categories[values.index(max(values))]}\n","    • Market share gap: {max(values)-min(values)}%\n","    \"\"\"\n","    ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n","    \n","    plt.tight_layout()\n","    \n","    # Save high-quality image\n","    output_path = 'detailed_infographic.png'\n","    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n","    plt.close()\n","    \n","    print(f\"Detailed infographic saved as: {output_path}\")\n","    return output_path\n","    print(f\"Detailed infographic saved as: {output_path}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:13:35.767541Z","iopub.status.busy":"2024-12-17T13:13:35.767279Z","iopub.status.idle":"2024-12-17T13:13:35.782809Z","shell.execute_reply":"2024-12-17T13:13:35.782118Z","shell.execute_reply.started":"2024-12-17T13:13:35.767510Z"},"trusted":true},"outputs":[],"source":["def convert_gif_to_storytelling_video(gif_path, text):\n","    \"\"\"\n","    Converts a GIF into a storytelling video using imageio\n","    \"\"\"\n","    import os\n","    from PIL import Image, ImageDraw, ImageFont\n","    import numpy as np\n","    import imageio\n","    \n","    # Process text for insights\n","    summary = nlp_pipeline(text, '')\n","    categories = summary['categories']\n","    values = summary['values']\n","    \n","    def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n","        img = Image.new('RGB', size, color=bg_color)\n","        draw = ImageDraw.Draw(img)\n","        \n","        try:\n","            font = ImageFont.truetype(\"arial.ttf\", 60)\n","        except:\n","            font = ImageFont.load_default()\n","        \n","        # Get text bbox\n","        bbox = draw.textbbox((0, 0), text, font=font)\n","        text_width = bbox[2] - bbox[0]\n","        text_height = bbox[3] - bbox[1]\n","        \n","        # Center text\n","        x = (size[0] - text_width) // 2\n","        y = (size[1] - text_height) // 2\n","        \n","        draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n","        # Convert to RGB numpy array\n","        return np.array(img.convert('RGB'))\n","    \n","    # Prepare frames\n","    frames = []\n","    fps = 30\n","    \n","    # 1. Title sequence (2 seconds)\n","    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n","    for _ in range(2 * fps):\n","        frames.append(title_frame)\n","    \n","    # 2. GIF sequence (4 seconds)\n","    gif = Image.open(gif_path)\n","    gif_frames = []\n","    try:\n","        while True:\n","            frame = gif.copy()\n","            # Resize frame and ensure RGB\n","            frame = frame.convert('RGB').resize((1920, 1080), Image.LANCZOS)\n","            # Convert to numpy array\n","            frame_array = np.array(frame)\n","            gif_frames.append(frame_array)\n","            gif.seek(len(gif_frames))\n","    except EOFError:\n","        pass\n","    \n","    # Extend gif frames to 4 seconds\n","    frames_needed = 4 * fps\n","    while len(gif_frames) < frames_needed:\n","        gif_frames.extend(gif_frames)\n","    frames.extend(gif_frames[:frames_needed])\n","    \n","    # 3. Explanation sequence (4 seconds)\n","    explanations = [\n","        \"Analyzing market share data...\",\n","        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n","        f\"Market gap analysis shows {max(values)-min(values)}% difference\",\n","        f\"Total market coverage: {sum(values)}%\",\n","        \"Generating insights and recommendations...\"\n","    ]\n","    \n","    frames_per_explanation = int((4 * fps) / len(explanations))\n","    for exp in explanations:\n","        exp_frame = create_text_frame(exp)\n","        for _ in range(frames_per_explanation):\n","            frames.append(exp_frame)\n","    \n","    # Verify all frames have same shape and channels\n","    frame_shape = frames[0].shape\n","    frames = [frame.reshape(frame_shape) if frame.shape != frame_shape else frame \n","             for frame in frames]\n","    \n","    # Save as MP4\n","    output_path = 'data_storytelling_video.mp4'\n","    \n","    print(\"Writing video...\")\n","    writer = imageio.get_writer(output_path, fps=fps)\n","    for frame in frames:\n","        writer.append_data(frame)\n","    writer.close()\n","    \n","    print(f\"Data storytelling video saved as: {output_path}\")\n","    return output_path"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:32:38.262931Z","iopub.status.busy":"2024-12-17T13:32:38.262487Z","iopub.status.idle":"2024-12-17T13:33:12.210707Z","shell.execute_reply":"2024-12-17T13:33:12.209389Z","shell.execute_reply.started":"2024-12-17T13:32:38.262895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating frames...\n","Creating GIF...\n","Cleanup completed successfully\n","Animation saved as GIF: animated_infographic.gif\n","Writing video...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = _posixsubprocess.fork_exec(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Data storytelling video saved as: data_storytelling_video.mp4\n"]}],"source":["# Create the animated GIF\n","gif_path = create_animated_gif('30% dogs use nokia and 90% use iphones')\n","\n","# Convert to storytelling video\n","video_path = convert_gif_to_storytelling_video(gif_path, '30% dogs use nokia and 90% use iphones')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.223169Z","iopub.status.busy":"2024-12-17T13:14:29.221836Z","iopub.status.idle":"2024-12-17T13:14:29.227296Z","shell.execute_reply":"2024-12-17T13:14:29.226473Z","shell.execute_reply.started":"2024-12-17T13:14:29.223135Z"},"trusted":true},"outputs":[],"source":["# # First create the animated GIF\n","# gif_path = create_animated_gif('20% users use iphone and 40% uses samsung')\n","\n","# # Then convert it to storytelling video\n","# video_path = convert_gif_to_storytelling_video(gif_path, '20% users use iphone and 40% uses samsung')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.228665Z","iopub.status.busy":"2024-12-17T13:14:29.228374Z","iopub.status.idle":"2024-12-17T13:14:29.241446Z","shell.execute_reply":"2024-12-17T13:14:29.240722Z","shell.execute_reply.started":"2024-12-17T13:14:29.228639Z"},"trusted":true},"outputs":[],"source":["# print(output_path)\n","# print(f\"Detailed infographic saved as: {output_path}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.242859Z","iopub.status.busy":"2024-12-17T13:14:29.242523Z","iopub.status.idle":"2024-12-17T13:14:29.251642Z","shell.execute_reply":"2024-12-17T13:14:29.250820Z","shell.execute_reply.started":"2024-12-17T13:14:29.242832Z"},"trusted":true},"outputs":[],"source":["\n","\n","# # Test the functions\n","# gif_path = create_animated_gif('20% users use iphone and 40% uses samsung')\n","# detailed_path = create_detailed_infographic('20% users use iphone and 40% uses samsung')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.253082Z","iopub.status.busy":"2024-12-17T13:14:29.252746Z","iopub.status.idle":"2024-12-17T13:14:29.263008Z","shell.execute_reply":"2024-12-17T13:14:29.262235Z","shell.execute_reply.started":"2024-12-17T13:14:29.253044Z"},"trusted":true},"outputs":[],"source":["# # Test the function\n","# gif_path, video_path = generate_animated_infographics('20% users use iphone and 40% uses samsung')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.264304Z","iopub.status.busy":"2024-12-17T13:14:29.264046Z","iopub.status.idle":"2024-12-17T13:14:29.278051Z","shell.execute_reply":"2024-12-17T13:14:29.277127Z","shell.execute_reply.started":"2024-12-17T13:14:29.264278Z"},"trusted":true},"outputs":[],"source":["# generate_infographics_from_csv('/kaggle/input/sample-sales-data/sales_data_sample.csv')\n","# # generate_infographics_from_prompt_and_csv('This is a custom prompt', 'data.csv')\n","# # generate_high_quality_infographics_from_text('20% users use iphone and 40% uses samsung')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-12-17T13:14:29.279462Z","iopub.status.busy":"2024-12-17T13:14:29.279176Z","iopub.status.idle":"2024-12-17T13:14:29.288276Z","shell.execute_reply":"2024-12-17T13:14:29.287616Z","shell.execute_reply.started":"2024-12-17T13:14:29.279434Z"},"trusted":true},"outputs":[],"source":["# for today its done date 3 Dec\n","\n","#  Backup Code for Model Development "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":435,"sourceId":896,"sourceType":"datasetVersion"}],"dockerImageVersionId":30804,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
